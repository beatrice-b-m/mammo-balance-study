{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbrow51/.conda/envs/torch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from modelV2.tune import HyperParamOptimizer\n",
    "from modelV2.train import tuning_wrapper\n",
    "# from modelV2.arch.rn_2 import ResNet18\n",
    "from torchvision.transforms import v2\n",
    "import os\n",
    "import re\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_masked_path(target_mask_factor: str, mask_factors_str: str, masked_paths_str: str):\n",
    "    try:\n",
    "        # parse the mask factors/masked path strings\n",
    "        mask_factors_list = parse_mask_factors(mask_factors_str)\n",
    "        mask_paths_list = parse_masked_paths(masked_paths_str)\n",
    "\n",
    "        # find the index of the target mask factor\n",
    "        target_idx = mask_factors_list.index(target_mask_factor)\n",
    "\n",
    "        # extract the target masked path\n",
    "        return mask_paths_list[target_idx]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return 'CAUGHT_ERROR'\n",
    "\n",
    "def parse_mask_factors(mask_factors_str: str):\n",
    "    # remove brackets and spaces from the string\n",
    "    mask_factors_str = mask_factors_str.translate({ord(c): None for c in \"][ \"})\n",
    "    # the split on commas\n",
    "    return mask_factors_str.split(',')\n",
    "\n",
    "def parse_masked_paths(masked_paths_str: str):\n",
    "    # split on dollar characters (pls dont have any of these in your paths!!)\n",
    "    return masked_paths_str.split('$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 49713\n",
    "BASE_DIR = \"/mnt/NAS3/DataBalance/balance-study/data/images/run_e1_a_1200_800/\"\n",
    "MASK_STR = \"0_0\"\n",
    "BALANCE_DISTRIBUTIONS = False\n",
    "\n",
    "N_BOOTSTRAPS = 5\n",
    "EPOCHS_PER_RUN = 20\n",
    "MONITOR_METRIC = 'loss'\n",
    "HPARAM_RANGE_DICT = {\n",
    "    'learning_rate': (0.00001, 0.01),\n",
    "}\n",
    "\n",
    "\n",
    "BATCH_SIZE = 48\n",
    "N_RANDOM = 5\n",
    "N_GUIDED = 10\n",
    "MODEL_NAME = f\"masked_{MASK_STR}_rn18_r3_a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assigned_split\n",
      "train             4485\n",
      "test               986\n",
      "val                955\n",
      "Name: count, dtype: int64\n",
      "assigned_split\n",
      "train             45232\n",
      "val                9743\n",
      "test                991\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pos_df = pd.read_csv(os.path.join(BASE_DIR, \"pos_out_df.csv\"))\n",
    "neg_df = pd.read_csv(os.path.join(BASE_DIR, \"neg_proc_df.csv\"))\n",
    "\n",
    "# only include exams we've assigned to the tuning set\n",
    "# this is done so evaluation class balance is consistent \n",
    "# between train/val/test sets\n",
    "# 10/90 balance testing can be done after tuning is completed\n",
    "neg_df = neg_df[neg_df[\"include_in_tuning\"] == 1]\n",
    "\n",
    "pos_df.dropna(subset=['masked_factors', 'masked_png_paths'], inplace=True)\n",
    "neg_df.dropna(subset=['masked_factors', 'masked_png_paths'], inplace=True)\n",
    "print(pos_df[['assigned_split']].value_counts())\n",
    "print(neg_df[['assigned_split']].value_counts())\n",
    "\n",
    "def correct_paths_to_kraken(hiti_path):\n",
    "    replace_str = r\"/mnt/NAS3/DataBalance/balance-study\\1\"\n",
    "    # use re.sub to replace everything before '/data/images'\n",
    "    return re.sub(r'^.*?(/data/images)', replace_str, hiti_path)\n",
    "\n",
    "pos_df['__target_path'] = pos_df.apply(\n",
    "    lambda x: correct_paths_to_kraken(extract_masked_path(\n",
    "        MASK_STR.replace('_', '.'), \n",
    "        x.masked_factors, \n",
    "        x.masked_png_paths\n",
    "    )), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "neg_df['__target_path'] = neg_df.apply(\n",
    "    lambda x: correct_paths_to_kraken(extract_masked_path(\n",
    "        MASK_STR.replace('_', '.'), \n",
    "        x.masked_factors, \n",
    "        x.masked_png_paths\n",
    "    )), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "DF_POOL_DICT = {\n",
    "    \"pos\": {\n",
    "        \"train\": pos_df[pos_df.assigned_split == \"train\"],\n",
    "        \"val\": pos_df[pos_df.assigned_split == \"val\"],\n",
    "        \"test\": pos_df[pos_df.assigned_split == \"test\"]\n",
    "    },\n",
    "    \"neg\": {\n",
    "        \"train\": neg_df[neg_df.assigned_split == \"train\"],\n",
    "        \"val\": neg_df[neg_df.assigned_split == \"val\"],\n",
    "        \"test\": neg_df[neg_df.assigned_split == \"test\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENT_DICT = {\n",
    "    'crop': {\n",
    "        'enabled': True, \n",
    "        'func': v2.RandomResizedCrop,\n",
    "        'prob': 1.0,\n",
    "        'params': {\n",
    "            'size': (1200, 800), \n",
    "            'scale': (0.7, 1.0),\n",
    "        }\n",
    "    },\n",
    "    'rotation': { \n",
    "        'enabled': True, \n",
    "        'func': v2.RandomRotation,\n",
    "        'prob': 0.4,\n",
    "        'params': {\n",
    "            'degrees': 5\n",
    "        }\n",
    "    },\n",
    "    'color_jitter': {\n",
    "        'enabled': True,\n",
    "        'func': v2.ColorJitter,\n",
    "        'prob': 0.2,\n",
    "        'params': {\n",
    "            'brightness': 0.4, \n",
    "            'contrast': 0.4,\n",
    "            'saturation': 0.4, \n",
    "            'hue': 0.2\n",
    "        }\n",
    "    },\n",
    "    'gaussian_blur': {\n",
    "        'enabled': True,\n",
    "        'func': v2.GaussianBlur,\n",
    "        'prob': 0.2,\n",
    "        'params': {\n",
    "            'kernel_size': 3\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device...\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"using {device} device...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded...\n",
      "\n",
      "Optimizing model ------------------------------------------------------------\n",
      "Logging results to './logs/masked_0_0_rn18_r3_a_opt.json'\n",
      "|   iter    |  target   | learni... |\n",
      "-------------------------------------\n",
      "running 5 bootstraps...\n",
      "with seeds: [4266198 9960322 3226871 5341026  569431]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/NAS3/DataBalance/balance-study/mammo-balance-study/modelV2/data.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pos_df.loc[:, '__class'] = 1\n",
      "/mnt/NAS3/DataBalance/balance-study/mammo-balance-study/modelV2/data.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  neg_df.loc[:, '__class'] = 0\n",
      "/home/tbrow51/.conda/envs/torch/lib/python3.9/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:20<00:00,  1.63batch/s, train_loss=0.692, train_acc=0.523, train_auc=0.555, train_f1=0.656, train_prec=0.513, train_rec=0.911]\n",
      "100%|██████████| 28/28 [00:18<00:00,  1.51batch/s, val_loss=0.691, val_acc=0.532, val_auc=0.56, val_f1=0.659, val_prec=0.518, val_rec=0.906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with best val_loss '0.6912'...\n",
      "\n",
      "Epoch 1 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:24<00:00,  1.56batch/s, train_loss=0.691, train_acc=0.54, train_auc=0.558, train_f1=0.643, train_prec=0.526, train_rec=0.829] \n",
      "100%|██████████| 28/28 [00:18<00:00,  1.50batch/s, val_loss=0.692, val_acc=0.519, val_auc=0.526, val_f1=0.629, val_prec=0.512, val_rec=0.816]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:23<00:00,  1.57batch/s, train_loss=0.691, train_acc=0.546, train_auc=0.558, train_f1=0.627, train_prec=0.532, train_rec=0.761]\n",
      "100%|██████████| 28/28 [00:19<00:00,  1.43batch/s, val_loss=0.691, val_acc=0.523, val_auc=0.544, val_f1=0.48, val_prec=0.528, val_rec=0.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with best val_loss '0.6910'...\n",
      "\n",
      "Epoch 3 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:23<00:00,  1.57batch/s, train_loss=0.69, train_acc=0.546, train_auc=0.564, train_f1=0.595, train_prec=0.537, train_rec=0.666]\n",
      "100%|██████████| 28/28 [00:18<00:00,  1.49batch/s, val_loss=0.69, val_acc=0.548, val_auc=0.568, val_f1=0.614, val_prec=0.536, val_rec=0.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with best val_loss '0.6904'...\n",
      "\n",
      "Epoch 4 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:25<00:00,  1.53batch/s, train_loss=0.69, train_acc=0.549, train_auc=0.567, train_f1=0.573, train_prec=0.544, train_rec=0.605]\n",
      "100%|██████████| 28/28 [00:20<00:00,  1.39batch/s, val_loss=0.69, val_acc=0.564, val_auc=0.569, val_f1=0.564, val_prec=0.564, val_rec=0.564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with best val_loss '0.6903'...\n",
      "\n",
      "Epoch 5 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:22<00:00,  1.59batch/s, train_loss=0.69, train_acc=0.552, train_auc=0.571, train_f1=0.552, train_prec=0.553, train_rec=0.551]\n",
      "100%|██████████| 28/28 [00:19<00:00,  1.43batch/s, val_loss=0.69, val_acc=0.532, val_auc=0.558, val_f1=0.427, val_prec=0.551, val_rec=0.349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with best val_loss '0.6897'...\n",
      "\n",
      "Epoch 6 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:23<00:00,  1.57batch/s, train_loss=0.69, train_acc=0.544, train_auc=0.564, train_f1=0.58, train_prec=0.537, train_rec=0.631] \n",
      "100%|██████████| 28/28 [00:19<00:00,  1.40batch/s, val_loss=0.689, val_acc=0.549, val_auc=0.574, val_f1=0.538, val_prec=0.551, val_rec=0.525]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with best val_loss '0.6890'...\n",
      "\n",
      "Epoch 7 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:23<00:00,  1.56batch/s, train_loss=0.689, train_acc=0.549, train_auc=0.574, train_f1=0.543, train_prec=0.55, train_rec=0.535] \n",
      "100%|██████████| 28/28 [00:19<00:00,  1.40batch/s, val_loss=0.69, val_acc=0.546, val_auc=0.575, val_f1=0.638, val_prec=0.53, val_rec=0.802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:24<00:00,  1.54batch/s, train_loss=0.69, train_acc=0.54, train_auc=0.565, train_f1=0.551, train_prec=0.538, train_rec=0.564]  \n",
      "100%|██████████| 28/28 [00:19<00:00,  1.44batch/s, val_loss=0.689, val_acc=0.534, val_auc=0.566, val_f1=0.59, val_prec=0.526, val_rec=0.672]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:23<00:00,  1.58batch/s, train_loss=0.689, train_acc=0.549, train_auc=0.577, train_f1=0.56, train_prec=0.546, train_rec=0.573] \n",
      "100%|██████████| 28/28 [00:18<00:00,  1.49batch/s, val_loss=0.688, val_acc=0.576, val_auc=0.599, val_f1=0.55, val_prec=0.585, val_rec=0.518]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with best val_loss '0.6880'...\n",
      "\n",
      "Epoch 10 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:24<00:00,  1.55batch/s, train_loss=0.689, train_acc=0.542, train_auc=0.57, train_f1=0.524, train_prec=0.546, train_rec=0.505] \n",
      "100%|██████████| 28/28 [00:19<00:00,  1.44batch/s, val_loss=0.689, val_acc=0.541, val_auc=0.573, val_f1=0.538, val_prec=0.542, val_rec=0.534]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:28<00:00,  1.47batch/s, train_loss=0.689, train_acc=0.547, train_auc=0.571, train_f1=0.556, train_prec=0.545, train_rec=0.568]\n",
      "100%|██████████| 28/28 [00:20<00:00,  1.39batch/s, val_loss=0.69, val_acc=0.542, val_auc=0.56, val_f1=0.547, val_prec=0.541, val_rec=0.554]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:23<00:00,  1.58batch/s, train_loss=0.688, train_acc=0.554, train_auc=0.579, train_f1=0.56, train_prec=0.552, train_rec=0.568] \n",
      "100%|██████████| 28/28 [00:19<00:00,  1.41batch/s, val_loss=0.689, val_acc=0.546, val_auc=0.568, val_f1=0.557, val_prec=0.544, val_rec=0.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:21<00:00,  1.60batch/s, train_loss=0.688, train_acc=0.557, train_auc=0.582, train_f1=0.585, train_prec=0.551, train_rec=0.624]\n",
      "100%|██████████| 28/28 [00:20<00:00,  1.37batch/s, val_loss=0.687, val_acc=0.551, val_auc=0.586, val_f1=0.508, val_prec=0.562, val_rec=0.464]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with best val_loss '0.6873'...\n",
      "\n",
      "Epoch 14 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:23<00:00,  1.57batch/s, train_loss=0.688, train_acc=0.547, train_auc=0.578, train_f1=0.55, train_prec=0.547, train_rec=0.554] \n",
      "100%|██████████| 28/28 [00:19<00:00,  1.45batch/s, val_loss=0.689, val_acc=0.54, val_auc=0.564, val_f1=0.575, val_prec=0.535, val_rec=0.621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:29<00:00,  1.46batch/s, train_loss=0.687, train_acc=0.551, train_auc=0.582, train_f1=0.561, train_prec=0.549, train_rec=0.572]\n",
      "100%|██████████| 28/28 [00:19<00:00,  1.41batch/s, val_loss=0.689, val_acc=0.537, val_auc=0.55, val_f1=0.535, val_prec=0.538, val_rec=0.531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:23<00:00,  1.57batch/s, train_loss=0.688, train_acc=0.554, train_auc=0.576, train_f1=0.562, train_prec=0.552, train_rec=0.572]\n",
      "100%|██████████| 28/28 [00:19<00:00,  1.44batch/s, val_loss=0.688, val_acc=0.537, val_auc=0.565, val_f1=0.592, val_prec=0.529, val_rec=0.672]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:24<00:00,  1.55batch/s, train_loss=0.687, train_acc=0.553, train_auc=0.577, train_f1=0.56, train_prec=0.551, train_rec=0.57]  \n",
      "100%|██████████| 28/28 [00:20<00:00,  1.36batch/s, val_loss=0.688, val_acc=0.54, val_auc=0.574, val_f1=0.581, val_prec=0.533, val_rec=0.639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:22<00:00,  1.59batch/s, train_loss=0.687, train_acc=0.555, train_auc=0.576, train_f1=0.57, train_prec=0.551, train_rec=0.59]  \n",
      "100%|██████████| 28/28 [00:19<00:00,  1.46batch/s, val_loss=0.689, val_acc=0.533, val_auc=0.561, val_f1=0.549, val_prec=0.531, val_rec=0.569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:25<00:00,  1.54batch/s, train_loss=0.688, train_acc=0.542, train_auc=0.568, train_f1=0.545, train_prec=0.541, train_rec=0.55] \n",
      "100%|██████████| 28/28 [00:20<00:00,  1.40batch/s, val_loss=0.687, val_acc=0.551, val_auc=0.58, val_f1=0.598, val_prec=0.541, val_rec=0.669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with best val_loss '0.6866'...\n",
      "best model loaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:19<00:00,  1.45batch/s, val_loss=0.687, val_acc=0.554, val_auc=0.577, val_f1=0.596, val_prec=0.545, val_rec=0.657]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'test_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 25\u001b[0m\n\u001b[1;32m     18\u001b[0m hparam_optimizer\u001b[38;5;241m.\u001b[39mload_data(\n\u001b[1;32m     19\u001b[0m     df_pool_dict\u001b[38;5;241m=\u001b[39mDF_POOL_DICT,\n\u001b[1;32m     20\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[1;32m     21\u001b[0m     augment_dict\u001b[38;5;241m=\u001b[39mAUGMENT_DICT\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# start optimizer\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mhparam_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtuning_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_random\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_RANDOM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_guided\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_GUIDED\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_NAME\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/NAS3/DataBalance/balance-study/mammo-balance-study/modelV2/tune.py:88\u001b[0m, in \u001b[0;36mHyperParamOptimizer.optimize\u001b[0;34m(self, objective, n_random, n_guided, model_name)\u001b[0m\n\u001b[1;32m     81\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m BayesianOptimization(\n\u001b[1;32m     82\u001b[0m     f\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective_wrapper,\n\u001b[1;32m     83\u001b[0m     pbounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparam_range_dict,\n\u001b[1;32m     84\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed\n\u001b[1;32m     85\u001b[0m )\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# maximize f1 with hyperparams\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_random\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_guided\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# open the log file\u001b[39;00m\n\u001b[1;32m     91\u001b[0m opt_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(log_path, lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py:310\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    308\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggest(util)\n\u001b[1;32m    309\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_probe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer \u001b[38;5;129;01mand\u001b[39;00m iteration \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;66;03m# The bounds transformer should only modify the bounds after\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# the init_points points (only for the true iterations)\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_bounds(\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space))\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py:208\u001b[0m, in \u001b[0;36mBayesianOptimization.probe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39madd(params)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(Events\u001b[38;5;241m.\u001b[39mOPTIMIZATION_STEP)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/bayes_opt/target_space.py:236\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    234\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_as_array(params)\n\u001b[1;32m    235\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keys, x))\n\u001b[0;32m--> 236\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister(x, target)\n",
      "File \u001b[0;32m/mnt/NAS3/DataBalance/balance-study/mammo-balance-study/modelV2/tune.py:201\u001b[0m, in \u001b[0;36mHyperParamOptimizer.objective_wrapper\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, seed \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(bootstrap_seeds):\n\u001b[1;32m    199\u001b[0m     loader_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_bootstrap_dataloader(seed)\n\u001b[0;32m--> 201\u001b[0m     eval_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap_objective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbootstrap \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_metric\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    203\u001b[0m     run_evals\u001b[38;5;241m.\u001b[39mappend(eval_metric)\n",
      "File \u001b[0;32m/mnt/NAS3/DataBalance/balance-study/mammo-balance-study/modelV2/tune.py:220\u001b[0m, in \u001b[0;36mHyperParamOptimizer.bootstrap_objective\u001b[0;34m(self, loader_dict, kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective_function(\n\u001b[1;32m    209\u001b[0m     model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type, \n\u001b[1;32m    210\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m     last_phase\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# tune on the validation set so we don't overfit to test set\u001b[39;00m\n\u001b[1;32m    218\u001b[0m )\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# it's still called .test tho... so still load it the same way so i don't have to change all the code\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m eval_metric \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_monitor_metric\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# if using loss, multiply by -1 so we can maximize it\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_monitor_metric\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'test_loss'"
     ]
    }
   ],
   "source": [
    "# get optimizer\n",
    "hparam_optimizer = HyperParamOptimizer(\n",
    "    hparam_range_dict=HPARAM_RANGE_DICT, \n",
    "    balance=BALANCE_DISTRIBUTIONS,\n",
    "    monitor_metric=MONITOR_METRIC,\n",
    "    n_bootstraps=N_BOOTSTRAPS,\n",
    "    epochs_per_run=EPOCHS_PER_RUN,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# set device and model\n",
    "hparam_optimizer.set_model(\n",
    "    device=device, \n",
    "    model_type='resnet18'\n",
    ")\n",
    "\n",
    "# load data into optimizer\n",
    "hparam_optimizer.load_data(\n",
    "    df_pool_dict=DF_POOL_DICT,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    augment_dict=AUGMENT_DICT\n",
    ")\n",
    "\n",
    "# start optimizer\n",
    "hparam_optimizer.optimize(\n",
    "    objective=tuning_wrapper,\n",
    "    n_random=N_RANDOM, \n",
    "    n_guided=N_GUIDED, \n",
    "    model_name=MODEL_NAME\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
