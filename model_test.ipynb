{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbrow51/.conda/envs/torch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import torch\n",
    "from modelV2.tune import HyperParamOptimizer\n",
    "from modelV2.train import tuning_wrapper\n",
    "# from modelV2.arch.rn_2 import ResNet18\n",
    "from torchvision.transforms import v2\n",
    "import os\n",
    "import re\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_masked_path(target_mask_factor: str, mask_factors_str: str, masked_paths_str: str):\n",
    "    try:\n",
    "        # parse the mask factors/masked path strings\n",
    "        mask_factors_list = parse_mask_factors(mask_factors_str)\n",
    "        mask_paths_list = parse_masked_paths(masked_paths_str)\n",
    "\n",
    "        # find the index of the target mask factor\n",
    "        target_idx = mask_factors_list.index(target_mask_factor)\n",
    "\n",
    "        # extract the target masked path\n",
    "        return mask_paths_list[target_idx]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return 'CAUGHT_ERROR'\n",
    "\n",
    "def parse_mask_factors(mask_factors_str: str):\n",
    "    # remove brackets and spaces from the string\n",
    "    mask_factors_str = mask_factors_str.translate({ord(c): None for c in \"][ \"})\n",
    "    # the split on commas\n",
    "    return mask_factors_str.split(',')\n",
    "\n",
    "def parse_masked_paths(masked_paths_str: str):\n",
    "    # split on dollar characters (pls dont have any of these in your paths!!)\n",
    "    return masked_paths_str.split('$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 49713\n",
    "BASE_DIR = \"/mnt/NAS3/DataBalance/balance-study/data/images/run_e1_a_1200_800/\"\n",
    "MASK_STR = \"0_0\"\n",
    "BALANCE_DISTRIBUTIONS = True\n",
    "\n",
    "N_BOOTSTRAPS = 2\n",
    "EPOCHS_PER_RUN = 1\n",
    "MONITOR_METRIC = 'loss'\n",
    "HPARAM_RANGE_DICT = {\n",
    "    'learning_rate': (0.00001, 0.01),\n",
    "}\n",
    "\n",
    "\n",
    "BATCH_SIZE = 48\n",
    "N_RANDOM = 5\n",
    "N_GUIDED = 10\n",
    "MODEL_NAME = f\"rn18_no_bal_a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assigned_split\n",
      "train             4485\n",
      "test               986\n",
      "val                955\n",
      "Name: count, dtype: int64\n",
      "assigned_split\n",
      "train             45232\n",
      "val                9743\n",
      "test                991\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pos_df = pd.read_csv(os.path.join(BASE_DIR, \"pos_out_df.csv\"))\n",
    "neg_df = pd.read_csv(os.path.join(BASE_DIR, \"neg_proc_df.csv\"))\n",
    "\n",
    "# only include exams we've assigned to the tuning set\n",
    "# this is done so evaluation class balance is consistent \n",
    "# between train/val/test sets\n",
    "# 10/90 balance testing can be done after tuning is completed\n",
    "neg_df = neg_df[neg_df[\"include_in_tuning\"] == 1]\n",
    "\n",
    "pos_df.dropna(subset=['masked_factors', 'masked_png_paths'], inplace=True)\n",
    "neg_df.dropna(subset=['masked_factors', 'masked_png_paths'], inplace=True)\n",
    "print(pos_df[['assigned_split']].value_counts())\n",
    "print(neg_df[['assigned_split']].value_counts())\n",
    "\n",
    "def correct_paths_to_kraken(hiti_path):\n",
    "    replace_str = r\"/mnt/NAS3/DataBalance/balance-study\\1\"\n",
    "    # use re.sub to replace everything before '/data/images'\n",
    "    return re.sub(r'^.*?(/data/images)', replace_str, hiti_path)\n",
    "\n",
    "pos_df['__target_path'] = pos_df.apply(\n",
    "    lambda x: correct_paths_to_kraken(extract_masked_path(\n",
    "        MASK_STR.replace('_', '.'), \n",
    "        x.masked_factors, \n",
    "        x.masked_png_paths\n",
    "    )), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "neg_df['__target_path'] = neg_df.apply(\n",
    "    lambda x: correct_paths_to_kraken(extract_masked_path(\n",
    "        MASK_STR.replace('_', '.'), \n",
    "        x.masked_factors, \n",
    "        x.masked_png_paths\n",
    "    )), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "DF_POOL_DICT = {\n",
    "    \"pos\": {\n",
    "        \"train\": pos_df[pos_df.assigned_split == \"train\"],\n",
    "        \"val\": pos_df[pos_df.assigned_split == \"val\"],\n",
    "        \"test\": pos_df[pos_df.assigned_split == \"test\"]\n",
    "    },\n",
    "    \"neg\": {\n",
    "        \"train\": neg_df[neg_df.assigned_split == \"train\"],\n",
    "        \"val\": neg_df[neg_df.assigned_split == \"val\"],\n",
    "        \"test\": neg_df[neg_df.assigned_split == \"test\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENT_DICT = {\n",
    "    'crop': {\n",
    "        'enabled': True, \n",
    "        'func': v2.RandomResizedCrop,\n",
    "        'prob': 1.0,\n",
    "        'params': {\n",
    "            'size': (1200, 800), \n",
    "            'scale': (0.7, 1.0),\n",
    "        }\n",
    "    },\n",
    "    'rotation': { \n",
    "        'enabled': True, \n",
    "        'func': v2.RandomRotation,\n",
    "        'prob': 0.4,\n",
    "        'params': {\n",
    "            'degrees': 5\n",
    "        }\n",
    "    },\n",
    "    'color_jitter': {\n",
    "        'enabled': True,\n",
    "        'func': v2.ColorJitter,\n",
    "        'prob': 0.2,\n",
    "        'params': {\n",
    "            'brightness': 0.4, \n",
    "            'contrast': 0.4,\n",
    "            'saturation': 0.4, \n",
    "            'hue': 0.2\n",
    "        }\n",
    "    },\n",
    "    'gaussian_blur': {\n",
    "        'enabled': True,\n",
    "        'func': v2.GaussianBlur,\n",
    "        'prob': 0.2,\n",
    "        'params': {\n",
    "            'kernel_size': 3\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device...\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"using {device} device...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded...\n",
      "\n",
      "Optimizing model ------------------------------------------------------------\n",
      "Logging results to './logs/rn18_no_bal_a/opt_log.json'\n",
      "|   iter    |  target   | learni... |\n",
      "-------------------------------------\n",
      "running 2 bootstraps...\n",
      "with seeds: [4266198 9960322]\n",
      "reference dataframe:\n",
      "Patients: 2,044\n",
      "Exams: 2,067\n",
      "Images: 3,139\n",
      "\n",
      "target dataframe:\n",
      "Patients: 24,189\n",
      "Exams: 38,648\n",
      "Images: 45,232\n",
      "\n",
      "balancing distribution based on tissueden, ViewPosition, Race\n",
      "\n",
      "balancing data with 1.00 : 1.00 ratio\n",
      "\n",
      "reference dataframe:\n",
      "Patients: 425\n",
      "Exams: 427\n",
      "Images: 668\n",
      "\n",
      "target dataframe:\n",
      "Patients: 5,184\n",
      "Exams: 8,293\n",
      "Images: 9,743\n",
      "\n",
      "balancing distribution based on tissueden, ViewPosition, Race\n",
      "\n",
      "balancing data with 1.00 : 1.00 ratio\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbrow51/.conda/envs/torch/lib/python3.9/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 59/131 [00:39<00:48,  1.49batch/s, train_loss=0.692, train_acc=0.526, train_auc=0.557, train_f1=0.656, train_prec=0.514, train_rec=0.904]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 25\u001b[0m\n\u001b[1;32m     18\u001b[0m hparam_optimizer\u001b[38;5;241m.\u001b[39mload_data(\n\u001b[1;32m     19\u001b[0m     df_pool_dict\u001b[38;5;241m=\u001b[39mDF_POOL_DICT,\n\u001b[1;32m     20\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[1;32m     21\u001b[0m     augment_dict\u001b[38;5;241m=\u001b[39mAUGMENT_DICT\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# start optimizer\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mhparam_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtuning_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_random\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_RANDOM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_guided\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_GUIDED\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_NAME\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/NAS3/DataBalance/balance-study/mammo-balance-study/modelV2/tune.py:116\u001b[0m, in \u001b[0;36mHyperParamOptimizer.optimize\u001b[0;34m(self, objective, n_random, n_guided, model_name)\u001b[0m\n\u001b[1;32m    109\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m BayesianOptimization(\n\u001b[1;32m    110\u001b[0m     f\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective_wrapper,\n\u001b[1;32m    111\u001b[0m     pbounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparam_range_dict,\n\u001b[1;32m    112\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed\n\u001b[1;32m    113\u001b[0m )\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# maximize f1 with hyperparams\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_random\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_guided\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# open the log file\u001b[39;00m\n\u001b[1;32m    119\u001b[0m opt_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(log_path, lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py:310\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    308\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggest(util)\n\u001b[1;32m    309\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_probe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer \u001b[38;5;129;01mand\u001b[39;00m iteration \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;66;03m# The bounds transformer should only modify the bounds after\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# the init_points points (only for the true iterations)\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_bounds(\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space))\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py:208\u001b[0m, in \u001b[0;36mBayesianOptimization.probe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39madd(params)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(Events\u001b[38;5;241m.\u001b[39mOPTIMIZATION_STEP)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/bayes_opt/target_space.py:236\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    234\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_as_array(params)\n\u001b[1;32m    235\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keys, x))\n\u001b[0;32m--> 236\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister(x, target)\n",
      "File \u001b[0;32m/mnt/NAS3/DataBalance/balance-study/mammo-balance-study/modelV2/tune.py:254\u001b[0m, in \u001b[0;36mHyperParamOptimizer.objective_wrapper\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboot_num \u001b[38;5;241m=\u001b[39m i\n\u001b[1;32m    252\u001b[0m loader_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_bootstrap_dataloader(seed)\n\u001b[0;32m--> 254\u001b[0m eval_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap_objective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbootstrap \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_metric\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    256\u001b[0m run_evals\u001b[38;5;241m.\u001b[39mappend(eval_metric)\n",
      "File \u001b[0;32m/mnt/NAS3/DataBalance/balance-study/mammo-balance-study/modelV2/tune.py:261\u001b[0m, in \u001b[0;36mHyperParamOptimizer.bootstrap_objective\u001b[0;34m(self, loader_dict, kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbootstrap_objective\u001b[39m(\u001b[38;5;28mself\u001b[39m, loader_dict, kwargs): \u001b[38;5;66;03m# i need to think of a name for this\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs_per_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemp_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmonitor_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_monitor_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_phase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# tune on the validation set so we don't overfit to test set\u001b[39;49;00m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# it's still called .test tho... so still load it the same way so i don't have to change all the code\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     eval_metric \u001b[38;5;241m=\u001b[39m history[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtest[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_monitor_metric]\n",
      "File \u001b[0;32m/mnt/NAS3/DataBalance/balance-study/mammo-balance-study/modelV2/train.py:283\u001b[0m, in \u001b[0;36mtuning_wrapper\u001b[0;34m(model_type, device, loader_dict, kwargs, n_epochs, save_dir, monitor_metric, seed, last_phase)\u001b[0m\n\u001b[1;32m    280\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;66;03m# train the model and return the training history\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloader_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_collection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_collection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmonitor_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlast_phase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_phase\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m/mnt/NAS3/DataBalance/balance-study/mammo-balance-study/modelV2/train.py:83\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(device, model, loader_dict, metric_collection, criterion, optimizer, n_epochs, save_dir, monitor_metric, last_phase)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# perform train/val phases\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m phase \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 83\u001b[0m     phase_metrics_dict \u001b[38;5;241m=\u001b[39m \u001b[43mepoch_phase\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mphase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mphase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_collection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_collection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# add current phase dict to the epoch metrics object\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(epoch_metrics_object, phase, phase_metrics_dict)\n",
      "File \u001b[0;32m/mnt/NAS3/DataBalance/balance-study/mammo-balance-study/modelV2/train.py:194\u001b[0m, in \u001b[0;36mepoch_phase\u001b[0;34m(phase, device, model, loader_dict, metric_collection, criterion, optimizer)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iter):\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# unpack data and send them to the device\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m--> 194\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, y\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m# zero the parameter gradients\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get optimizer\n",
    "hparam_optimizer = HyperParamOptimizer(\n",
    "    hparam_range_dict=HPARAM_RANGE_DICT, \n",
    "    balance=BALANCE_DISTRIBUTIONS,\n",
    "    monitor_metric=MONITOR_METRIC,\n",
    "    n_bootstraps=N_BOOTSTRAPS,\n",
    "    epochs_per_run=EPOCHS_PER_RUN,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# set device and model\n",
    "hparam_optimizer.set_model(\n",
    "    device=device, \n",
    "    model_type='resnet18'\n",
    ")\n",
    "\n",
    "# load data into optimizer\n",
    "hparam_optimizer.load_data(\n",
    "    df_pool_dict=DF_POOL_DICT,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    augment_dict=AUGMENT_DICT\n",
    ")\n",
    "\n",
    "# start optimizer\n",
    "hparam_optimizer.optimize(\n",
    "    objective=tuning_wrapper,\n",
    "    n_random=N_RANDOM, \n",
    "    n_guided=N_GUIDED, \n",
    "    model_name=MODEL_NAME\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = pd.read_json(\"/mnt/NAS3/DataBalance/balance-study/mammo-balance-study/logs/rn18_no_bal_a/opt_log.json\", lines=True)\n",
    "# opt\n",
    "# # demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo = pd.read_json(\"/mnt/NAS3/DataBalance/balance-study/mammo-balance-study/logs/rn18_no_bal_a/demographics.json\", lines=True)\n",
    "# demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
