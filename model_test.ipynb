{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from modelV2.tune import HyperParamOptimizer\n",
    "from modelV2.train import tuning_wrapper\n",
    "# from modelV2.arch.rn_2 import ResNet18\n",
    "from torchvision.transforms import v2\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_masked_path(target_mask_factor: str, mask_factors_str: str, masked_paths_str: str):\n",
    "    try:\n",
    "        # parse the mask factors/masked path strings\n",
    "        mask_factors_list = parse_mask_factors(mask_factors_str)\n",
    "        mask_paths_list = parse_masked_paths(masked_paths_str)\n",
    "\n",
    "        # find the index of the target mask factor\n",
    "        target_idx = mask_factors_list.index(target_mask_factor)\n",
    "\n",
    "        # extract the target masked path\n",
    "        return mask_paths_list[target_idx]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return 'CAUGHT_ERROR'\n",
    "\n",
    "def parse_mask_factors(mask_factors_str: str):\n",
    "    # remove brackets and spaces from the string\n",
    "    mask_factors_str = mask_factors_str.translate({ord(c): None for c in \"][ \"})\n",
    "    # the split on commas\n",
    "    return mask_factors_str.split(',')\n",
    "\n",
    "def parse_masked_paths(masked_paths_str: str):\n",
    "    # split on dollar characters (pls dont have any of these in your paths!!)\n",
    "    return masked_paths_str.split('$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 49713\n",
    "BASE_DIR = \"/data/beatrice/mammo/balance-study/data/images/run_e1_a_1200_800/\"\n",
    "MASK_STR = \"0_0\"\n",
    "BALANCE_DISTRIBUTIONS = False\n",
    "\n",
    "N_BOOTSTRAPS = 5\n",
    "EPOCHS_PER_RUN = 20\n",
    "MONITOR_METRIC = 'loss'\n",
    "HPARAM_RANGE_DICT = {\n",
    "    'learning_rate': (0.00001, 0.01),\n",
    "}\n",
    "\n",
    "\n",
    "BATCH_SIZE = 48\n",
    "N_RANDOM = 5\n",
    "N_GUIDED = 10\n",
    "MODEL_NAME = f\"masked_{MASK_STR}_rn18_r3_a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = pd.read_csv(os.path.join(BASE_DIR, \"pos_out_df.csv\"))\n",
    "neg_df = pd.read_csv(os.path.join(BASE_DIR, \"neg_proc_df.csv\"))\n",
    "\n",
    "# only include exams we've assigned to the tuning set\n",
    "# this is done so evaluation class balance is consistent \n",
    "# between train/val/test sets\n",
    "# 10/90 balance testing can be done after tuning is completed\n",
    "neg_df = neg_df[neg_df[\"include_in_tuning\"] == 1]\n",
    "\n",
    "pos_df.dropna(subset=['masked_factors', 'masked_png_paths'], inplace=True)\n",
    "neg_df.dropna(subset=['masked_factors', 'masked_png_paths'], inplace=True)\n",
    "print(pos_df[['assigned_split']].value_counts())\n",
    "print(neg_df[['assigned_split']].value_counts())\n",
    "\n",
    "pos_df['__target_path'] = pos_df.apply(\n",
    "    lambda x: extract_masked_path(\n",
    "        MASK_STR.replace('_', '.'), \n",
    "        x.masked_factors, \n",
    "        x.masked_png_paths\n",
    "    ), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "neg_df['__target_path'] = neg_df.apply(\n",
    "    lambda x: extract_masked_path(\n",
    "        MASK_STR.replace('_', '.'), \n",
    "        x.masked_factors, \n",
    "        x.masked_png_paths\n",
    "    ), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "DF_POOL_DICT = {\n",
    "    \"pos\": {\n",
    "        \"train\": pos_df[pos_df.assigned_split == \"train\"],\n",
    "        \"val\": pos_df[pos_df.assigned_split == \"val\"],\n",
    "        \"test\": pos_df[pos_df.assigned_split == \"test\"]\n",
    "    },\n",
    "    \"neg\": {\n",
    "        \"train\": neg_df[neg_df.assigned_split == \"train\"],\n",
    "        \"val\": neg_df[neg_df.assigned_split == \"val\"],\n",
    "        \"test\": neg_df[neg_df.assigned_split == \"test\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENT_DICT = {\n",
    "    'crop': {\n",
    "        'enabled': True, \n",
    "        'func': v2.RandomResizedCrop,\n",
    "        'prob': 1.0,\n",
    "        'params': {\n",
    "            'size': (1200, 800), \n",
    "            'scale': (0.7, 1.0),\n",
    "        }\n",
    "    },\n",
    "    'rotation': { \n",
    "        'enabled': True, \n",
    "        'func': v2.RandomRotation,\n",
    "        'prob': 0.4,\n",
    "        'params': {\n",
    "            'degrees': 5\n",
    "        }\n",
    "    },\n",
    "    'color_jitter': {\n",
    "        'enabled': True,\n",
    "        'func': v2.ColorJitter,\n",
    "        'prob': 0.2,\n",
    "        'params': {\n",
    "            'brightness': 0.4, \n",
    "            'contrast': 0.4,\n",
    "            'saturation': 0.4, \n",
    "            'hue': 0.2\n",
    "        }\n",
    "    },\n",
    "    'gaussian_blur': {\n",
    "        'enabled': True,\n",
    "        'func': v2.GaussianBlur,\n",
    "        'prob': 0.2,\n",
    "        'params': {\n",
    "            'kernel_size': 3\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"using {device} device...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get optimizer\n",
    "hparam_optimizer = HyperParamOptimizer(\n",
    "    hparam_range_dict=HPARAM_RANGE_DICT, \n",
    "    balance=BALANCE_DISTRIBUTIONS,\n",
    "    monitor_metric=MONITOR_METRIC,\n",
    "    n_bootstraps=N_BOOTSTRAPS,\n",
    "    epochs_per_run=EPOCHS_PER_RUN,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# set device and model\n",
    "hparam_optimizer.set_model(\n",
    "    device=device, \n",
    "    model_type='resnet18'\n",
    ")\n",
    "\n",
    "# load data into optimizer\n",
    "hparam_optimizer.load_data(\n",
    "    df_pool_dict=DF_POOL_DICT,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    augment_dict=AUGMENT_DICT\n",
    ")\n",
    "\n",
    "# start optimizer\n",
    "hparam_optimizer.optimize(\n",
    "    objective=tuning_wrapper,\n",
    "    n_random=N_RANDOM, \n",
    "    n_guided=N_GUIDED, \n",
    "    model_name=MODEL_NAME\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
